{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data backup & sync and duplicate checker script for securing your files.\n",
    "You don't have to buy expensive backup softwares for this purpose, just use this simple script.\n",
    "You can with this script:\n",
    "   * check for equal, modifed, missing files between 2 folders\n",
    "        * the file comparison is based on filecmp library\n",
    "           * it uses file type, size, and modification time to compare, if one of the mentioned properties of both files are identical, the files are taken to be equal.\n",
    "        * you can specify file source destination too\n",
    "        * you can specify multiple directory, file pairs\n",
    "   * specify what operations to do copy new, update modified, delete files\n",
    "     * simulate actions, to see it works as expected\n",
    "   * search for duplicated files and see its sizes, similar files\n",
    "\n",
    "Planned functionalities\n",
    "   * exclude files, directories option\n",
    "\n",
    "improvements\n",
    "   * I only tested it with only one source, destination directory pair\n",
    "\n",
    "<font color=red>WARNING: Use this script at your own risk, check the code and understand better before you use it!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import filecmp\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def list_files_recursively(directory: str) -> list[str]:\n",
    "    \"\"\"Lists all files in a directory recursively\n",
    "\n",
    "    Args:\n",
    "        directory (str): directory to check\n",
    "\n",
    "    Returns:\n",
    "        list[str]: File list\n",
    "    \"\"\"    \n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_list.append(os.path.join(root, file))\n",
    "    return file_list\n",
    "\n",
    "def show_progress(total_c: int, act_idx: int, p_step: int = 5) -> None:\n",
    "    \"\"\"Shows the total progress in percents, which can be counted in advance\n",
    "\n",
    "    Args:\n",
    "        total_c (int): the total number of iterations in the progress\n",
    "        act_idx (int): the actual step in the progress\n",
    "        p_step (int, optional): The percent value, how frequently the script reports progress to the user. Defaults to 5.\n",
    "    \"\"\"    \n",
    "    step = 1/total_c * 100\n",
    "    p = ((act_idx/total_c) * 100)\n",
    "    rem = p % p_step\n",
    "    if rem < step:\n",
    "         print(f\"{round(p,2)}%\")\n",
    "\n",
    "def proc_row(df_len: int, i: int, f1: str, f2: str) -> bool:\n",
    "    \"\"\"The core file comparing function, it uses filecmp\n",
    "\n",
    "    Args:\n",
    "        df_len (int): The full length of the dataframe(each file pairs with similar names)\n",
    "        i (int): the actual index of the progress \n",
    "        f1 (str): filename1 to compare\n",
    "        f2 (str): filename2 to compare\n",
    "\n",
    "    Returns:\n",
    "        bool: if f1 and f2 seem to be identical it returns True otherwise returns False\n",
    "    \"\"\"\n",
    "\t\n",
    "\t# calc & show percentage\n",
    "    show_progress(df_len, i)\n",
    "\n",
    "\t# compare files\n",
    "    return filecmp.cmp(f1,f2)\n",
    "\n",
    "def calc_files_size(file_list_np_arr: np.ndarray) -> list[float]:\n",
    "    \"\"\"Calculates the file sizes of the specified file list in megabytes\n",
    "\n",
    "    Args:\n",
    "        file_list_np_arr (np.ndarray): The list of filepathes, comes from pandas Dataframe\n",
    "\n",
    "    Returns:\n",
    "        list[float]: the calculated file sizes in megabytes\n",
    "    \"\"\"    \n",
    "    stats_src = [Path(fp).stat() if not pd.isnull(fp) else None for fp in file_list_np_arr]\n",
    "    return list(map(lambda s: (s.st_size/1024/1024) if not pd.isnull(s) else None ,stats_src))\n",
    "\n",
    "def print_unique_dirs(df_filt: pd.DataFrame, action_str:str):\n",
    "    \"\"\"Shows the unique folders for a specified files with particular actions\n",
    "       Possible actions are COPY_NEW, UPDATE, DELETE\n",
    "\n",
    "    Args:\n",
    "        df_filt (pd.DataFrame): the pandas DataFrame object to filter\n",
    "        action_str (str): the caluclated action to do with the files\n",
    "    \"\"\"    \n",
    "    df_filt_tmp = df_filt.loc[df_filt['op'] == action_str]\n",
    "    if len(df_filt_tmp) > 0:\n",
    "        col = 'dst' if action_str == \"DELETE\" else 'src'\n",
    "        df_filt_tmp['dir'] = [os.path.dirname(f) for f in df_filt_tmp[col].values]\n",
    "        display(df_filt_tmp['dir'].unique().tolist())\n",
    "\n",
    "def print_files(df_filt: pd.DataFrame, action_str: str):\n",
    "    \"\"\"Print files with a particular action\n",
    "       Possible actions are COPY_NEW, UPDATE, DELETE\n",
    "\n",
    "    Args:\n",
    "        df_filt (pd.DataFrame): the pandas DataFrame object to filter\n",
    "        action_str (str): the caluclated action to do with the files\n",
    "    \"\"\"\n",
    "    col = 'dst' if action_str == \"DELETE\" else 'src'\n",
    "    display(df_filt.loc[df_filt['op'] == action_str][col].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################   Data backup & sync   #############################\n",
    "\n",
    "# --- INPUTS\n",
    "\n",
    "# decide to execute the particular action(DO IT CAREFULLY!)\n",
    "perform_copy_new = False \n",
    "perform_update = False\n",
    "perform_delete = False\n",
    "\n",
    "# you can specify here multiple pairs(should be tested more!)\n",
    "dir_file_arr = [{'src':'D:\\\\sample_source', 'dst': 'F:\\\\sample_source_backup'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- COLLECT SRC, DST FILE LISTS\n",
    "\n",
    "files_src_arr = []\n",
    "files_dst_arr = []\n",
    "dst_files_src_pathes = []\n",
    "src_files_dst_pathes = []\n",
    "\n",
    "# process directory, create file list\n",
    "for pathes in dir_file_arr:\n",
    "\n",
    "\t# path is directory\n",
    "\tif os.path.isdir(pathes['src']):\n",
    "\t\tsrc_act = list_files_recursively(pathes['src'])\n",
    "\t\tfiles_src_arr += src_act\n",
    "\t\tdst_act = list_files_recursively(pathes['dst'])\n",
    "\t\tfiles_dst_arr += dst_act\n",
    "\t\tdst_files_src_pathes += np.char.replace(dst_act, pathes['dst'], pathes['src']).tolist()\n",
    "\t\tsrc_files_dst_pathes += np.char.replace(src_act, pathes['src'], pathes['dst']).tolist()\n",
    "\t\n",
    "\t# path is file\n",
    "\telse:\n",
    "\t\tif os.path.exists(pathes['src']):\n",
    "\t\t\tfiles_src_arr.append(pathes['src'])\n",
    "\t\tif os.path.exists(pathes['dst']):\n",
    "\t\t\tfiles_dst_arr.append(pathes['dst'])\n",
    "            \n",
    "# caclulate missing files in both src and dst\n",
    "df_src = pd.DataFrame({'src': files_src_arr, 'src_dst': src_files_dst_pathes}, dtype=\"str\")\n",
    "df_dst = pd.DataFrame({'dst': files_dst_arr, 'dst_src': dst_files_src_pathes}, dtype=\"str\")\n",
    "df = pd.merge(df_dst,df_src, how= \"outer\", left_on= [\"dst\",\"dst_src\"], right_on= [\"src_dst\",\"src\"])\n",
    "\n",
    "df = df[['src', 'dst','src_dst']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PROCESSING\n",
    "\n",
    "# calc src file sizes\n",
    "df['src_size'] = calc_files_size(df['src'].values)\n",
    "\n",
    "# compare files\n",
    "df_len = len(df)\n",
    "df['src_dst_ident'] = [proc_row(df_len,r[0],r[1][0],r[1][1]) if r[1][0] is not np.nan and r[1][1] is not np.nan else False for r in enumerate(df.values)]\n",
    "\n",
    "# calculate file oparations\n",
    "df['op'] = '-'\n",
    "df.loc[df['src_dst_ident'] == True, 'op'] = 'NONE'\n",
    "df.loc[df['src_dst_ident'] == False, 'op'] = 'UPDATE'\n",
    "df.loc[df['dst'].isnull(), 'op'] = 'COPY_NEW'\n",
    "df.loc[df['src'].isnull(), 'op'] = 'DELETE'\n",
    "df.loc[df['dst'].isnull(), 'dst'] = df['src_dst']\n",
    "df.sort_values(['op', 'src'], inplace=True)\n",
    "\n",
    "# some stats about changes\n",
    "print(\"--------------\\n\\n\")\n",
    "print(df['op'].value_counts()) # if shows '-', something is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---SHOW DIRECTORIES AND FILES WITH PARTICULAR ACTIONS\n",
    "\n",
    "#print_unique_dirs(df_filt, 'COPY_NEW')\n",
    "print_files(df_filt, 'COPY_NEW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_unique_dirs(df_filt, 'UPDATE')\n",
    "print_files(df_filt, 'UPDATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_unique_dirs(df_filt, 'DELETE')\n",
    "print_files(df_filt, 'DELETE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---PERFORM ACTIONS\n",
    "\n",
    "df_filt = df[(df['op'] != 'NONE') & (df['op'] != '-')]\n",
    "\n",
    "# calc total sizes\n",
    "copy_new_size_mb = df_filt[df_filt['op'] == 'COPY_NEW']['src_size'].sum()\n",
    "update_size_mb = df_filt[df_filt['op'] == 'UPDATE']['src_size'].sum()\n",
    "delete_size_mb = df_filt[df_filt['op'] == 'DELETE']['src_size'].sum()\n",
    "\n",
    "print(f\"COPY_NEW total size {copy_new_size_mb} Mib\")\n",
    "print(f\"UPDATE total size {update_size_mb} Mib\")\n",
    "print(f\"DELETE total size {delete_size_mb} Mib\")\n",
    "\n",
    "print(f\"{len(df_filt)} actions total\")\n",
    "\n",
    "perform_actions = perform_copy_new | perform_update | perform_delete\n",
    "\n",
    "for i,r in df_filt.iterrows():\n",
    "\n",
    "\t# create dst dir if not checked, exist\n",
    "\tdst_dir = os.path.dirname(r['dst'])\n",
    "\n",
    "\t# create dst dir if not checked, exist\n",
    "\tif perform_actions and not os.path.exists(dst_dir):\n",
    "\t\tos.mkdir(dst_dir)\n",
    "\n",
    "\tif(r['op'] == 'COPY_NEW'):\n",
    "\n",
    "\t\tprint(f\"Processing COPY_NEW {r['src']}\")\n",
    "\t\tprint(f\"Processing COPY_NEW {r['dst']}\\n\")\n",
    "\n",
    "\t\tif perform_copy_new:\n",
    "\t\t\tshutil.copy(r['src'], r['dst'])\n",
    "\n",
    "\tif(r['op'] == 'UPDATE'):\n",
    "\t\tprint(f\"Processing UPDATE {r['src']}\")\n",
    "\t\tprint(f\"Processing UPDATE {r['dst']}\\n\")\n",
    "\n",
    "\t\tif perform_update:\n",
    "\t\t\tos.remove(r['dst'])\n",
    "\t\t\tshutil.copy(r['src'], r['dst'])\n",
    "\n",
    "\tif(r['op'] == 'DELETE'):\n",
    "\t\tprint(f\"Processing DELETE {r['dst']}\\n\")\n",
    "\n",
    "\t\tif perform_delete:\n",
    "\t\t\tos.remove(r['dst'])\n",
    "\n",
    "\t\t\t# delete empty folder\n",
    "\t\t\tif not os.listdir(dst_dir):\n",
    "\t\t\t\tos.rmdir(dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################   duplicate checker   #############################\n",
    "\n",
    "path = \"D:\\\\Gann\"\n",
    "mb_limit = 1\n",
    "\n",
    "# read file list\n",
    "files_arr = list_files_recursively(path)\n",
    "df = pd.DataFrame({'file': files_arr}, dtype=\"str\")\n",
    "\n",
    "# calc file size\n",
    "df['file_size'] = calc_files_size(df['file'].values)\n",
    "\n",
    "# filter by size\n",
    "df = df[df['file_size'] > mb_limit]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- COLLECT ALL DUPLICATES INTO STRUCTURE\n",
    "duplicate_arr = []\n",
    "total = pow(len(df['file'].values), 2)\n",
    "df_len = len(df)\n",
    "print(f\"Total elements to check: {total}, Analyzing...\")\n",
    "for i,f1 in enumerate(df['file'].values):\n",
    "    if not pd.isna(f1):\n",
    "        duplicate_arr.append({'file': f1, 'size': df['file_size'].values[i], 'dups': []})\n",
    "        for j,f2 in enumerate(df['file'].values):\n",
    "            show_progress(total, (i * df_len) + (j+1))\n",
    "            if f1 != f2 and not pd.isna(f2) and filecmp.cmp(f1,f2):\n",
    "                duplicate_arr[-1]['dups'].append(f2)\n",
    "duplicate_arr          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict -> dataframe\n",
    "duplicate_arr = [d for d in duplicate_arr if len(d['dups']) > 0]\n",
    "dup_counts = [len(d['dups']) for d in duplicate_arr]\n",
    "df_dup = pd.DataFrame(duplicate_arr, columns=['file', 'size', 'dups'])\n",
    "df_dup['dup_c'] = dup_counts\n",
    "df_dup.sort_values(['size'], inplace=True, ascending=False)\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---SHOW RESULTS WITH SIMPLE PRINT STATEMENT\n",
    "for i,dup_f in enumerate(df_dup['file'].values):\n",
    "    print(f\"{dup_f}\\n\")\n",
    "    print(f\"{df_dup['size'].values[i]}\\n\\n\")\n",
    "    for dup_f in df_dup['dups'].values[i]:\n",
    "        print(dup_f)\n",
    "    print(\"------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
